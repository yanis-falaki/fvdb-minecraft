{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fvdb\n",
    "from fvdb.nn import VDBTensor\n",
    "import torch\n",
    "from UNet import SparseUNet\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from utils import setup_plots, update_plots\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#fvdb.nn.SparseConv3d.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkDataset(Dataset):\n",
    "    def __init__(self, chunksPath):\n",
    "        self.paths = []\n",
    "\n",
    "        for filename in os.listdir(chunksPath):\n",
    "            self.paths.append(f\"{chunksPath}/{filename}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        grid_batch, labels, names = fvdb.load(self.paths[idx])\n",
    "        labels.to(torch.long)\n",
    "\n",
    "        return VDBTensor(grid_batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChunkDataset(\"data/training_data/chunks\")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size   # 20% for validation\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, collate_fn=fvdb.jcat, shuffle=True, prefetch_factor=4, num_workers=2)\n",
    "\n",
    "num_classes = 0\n",
    "with open(\"minecraft-serialization/block_list.txt\", 'r') as file:\n",
    "    num_classes = sum(1 for line in file)\n",
    "\n",
    "lr = 1e-4\n",
    "scheduler_step_size = 500\n",
    "scheduler_gamma = 0.1\n",
    "\n",
    "model = SparseUNet(num_classes).to('cuda')\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, scheduler_step_size, scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1, ax2, loss_line, acc_line = setup_plots()\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "iterations = []\n",
    "epochs = 1\n",
    "update_every = 10\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "steps_passed = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, vdb_tensor in enumerate(train_loader):\n",
    "        vdb_tensor = vdb_tensor.cuda()\n",
    "        target = vdb_tensor.data.jdata.squeeze().to(torch.long)\n",
    "        actives = vdb_tensor.grid.jagged_like(torch.ones(target.shape[0], device='cuda', dtype=torch.float32).unsqueeze(1))\n",
    "        X = VDBTensor(grid=vdb_tensor.grid, data=actives)\n",
    "\n",
    "        # forward and backward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        l = loss(y_hat.data.jdata, target)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # step scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        if steps_passed % update_every == 0:\n",
    "            # Calculate accuracy\n",
    "            predictions = torch.argmax(y_hat.data.jdata, dim=1)\n",
    "            acc = (predictions == target).float().mean()\n",
    "\n",
    "            losses.append(l.item())\n",
    "            accuracies.append(acc.item())\n",
    "            iterations.append(steps_passed)\n",
    "            update_plots(losses, accuracies, iterations, ax1, ax2, loss_line, acc_line)\n",
    "\n",
    "        # increment total steps passed\n",
    "        steps_passed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, collate_fn=fvdb.jcat, shuffle=True, prefetch_factor=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570cc67286b14dabb10416b081fa8c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation accuracy: 0.623\n"
     ]
    }
   ],
   "source": [
    "accuracy_sum = 0\n",
    "update_every = 10\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(), tqdm(total=len(val_loader)) as pbar:\n",
    "    for i, vdb_tensor in enumerate(val_loader):\n",
    "        vdb_tensor = vdb_tensor.cuda()\n",
    "        target = vdb_tensor.data.jdata.squeeze().to(torch.long)\n",
    "        actives = vdb_tensor.grid.jagged_like(torch.ones(target.shape[0], device='cuda', dtype=torch.float32).unsqueeze(1))\n",
    "\n",
    "        X = VDBTensor(grid=vdb_tensor.grid, data=actives)\n",
    "        y_hat = model(X)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predictions = torch.argmax(y_hat.data.jdata, dim=1)\n",
    "        accuracy_sum += (predictions == target).float().mean()\n",
    "\n",
    "        if (i + 1) % update_every == 0 or (i + 1) == len(val_loader):\n",
    "            current_mean = accuracy_sum / (i + 1)\n",
    "            pbar.set_description(f'Validating (Acc: {current_mean:.3f})')\n",
    "            pbar.update(update_every if i + 1 < len(val_loader) else len(val_loader) % update_every)\n",
    "\n",
    "mean_accuracy = accuracy_sum/len(val_loader)\n",
    "print(f'Final validation accuracy: {mean_accuracy:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fvdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
